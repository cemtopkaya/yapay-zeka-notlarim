## Course Overview

### Course Overview

Hi, everyone. It's a beautiful day to be alive. My name is Mohamed Echout, and welcome to my course, Prompt Engineering Best Practices. I am a technology lover with expertise in AI, data science, and prompt engineering. Did you know that generation AI can create anything from music to text making? It's a powerful tool for diverse creative endeavors. Learning it can unlock your potential automation and content management. This course will teach you everything you need to know to craft the perfect prompt to fully benefit from these new AI tools. Some of the major topics that we will cover include prompt design strategies, prompting methods, controlling model output with prompts, reducing repetition in prompts, and designing prompts for different tasks. By the end of this course, you will know how to craft perfect prompts to get the best output from AI generative tools and language models. This course is open to everyone. No matter what your level of expertise or background, I hope you will join me on this journey to learn the art of prompt engineering with the Prompt Engineering Best Practices course, at Pluralsight.

## Introduction to Prompt Engineering

### Introduction

Hello, everyone. In today's module, we're going to introduce prompt engineering and give it in a very simple, easy to understand definition. My name is Mohamed Echout, and I will be guiding you, and I will be your teammate into this amazing journey. In this module, we're going to cover the very basics. Let's start with a quick question, what is prompt engineering? It's always good to ask the W questions, so what, why, when, how? What is prompt engineering? How do we define it and how can we use it in our daily conversations? Because it's a good, new term, so it's really good to introduce it to our daily conversations. And to introduce it, we have to understand it. So we're going to define it clearly, but easily. Then the second question is why is prompt engineering important? Why do we care? So what are the main points that we should focus on while talking about prompt engineering and how do we think about prompt engineering from a very, very critical perspective? Last, but not least, we're going to speak about the evolution of prompt engineering in AI. So how did we get here? What are the main steps and stages? I made sure to simplify this section of this module. And I will cover the evolution of prompt engineering with you to make it easy for us to understand how did we get here and what will happen in the future? Up next, we're going to cover what is prompt engineering? So stay tuned. It's going to be an amazing section.

### What Is Prompt Engineering?

In this section, we're going to cover what is prompt engine and define what is this amazing new concept and how can we use it in our daily life? So, prompt engineering is writing clear instructions to guide an A I model to produce the desired to respond. So the main two variables there in the definition is clear instructions. As you know, when we deal with computers, it's all about giving the computer a clear set of steps, a clear instruction to explain everything to them from a very step by step process, very, very easy step by step perspective. So giving your A I model, your A I tool, clear set of instructions will enable us to get the best output and response for the task that we're trying to do. The objective here is why do we do this to get the desired response if we can use an A I tool to get what we need and what we want, which is a great response we're winning and we're using the power of prompt engineering in a very, very creative manner. So next is I just created a simplified diagram, but very easy to understand diagram to explain prompt engineering from a very, very perhaps a visual perspective to give us a little bit some context of how do we implement it and what goes underneath the hood. So let's start, we have some input. So we have an input box. What do you type in normally a question and some context based on the following article, what is the definition of data science? So you ask the A I A model, the computer the to a question and then you give it some context. The context can be a Wikipedia page, an article, a blog post that you wrote something where you guide the A I model, you guide the uh uh tool of how to give you a great great input. So the input is always combined or contains these two main variable question context. Once to write the input, the next step is you have to feed the input to an A I. The tool can be charge GP G, it can be major and it can be any tool out there that takes prompt as an input. And once you feed it, the next step would be you get a response, a very simplified response. If you're looking for some text, you're gonna get text. If you're looking for an image, you gotta go to get an image. And if you're looking for an A G, we have a lot of audio generative tools, code generative tools. The sky is the limit here. So the very three step process we start with an input that contains a question and a context, then we have an A I tool that takes that question and produces a great response for us. All right, now let's try to define one engine from a very, very perhaps doomy perspective. So I created the detailed diagram for us that we're going to discover together. We start with an input box that takes your prompt and this input box will contain the following variables to or tonality. It is simply the mood or emotional quality of your message. Do you want your message or your output to be friendly? Serious academic formal? How do you want your output to be crafted from an emotional perspective? Next is the link. How long or short do you want your output to be 500 words? 10 words, 5000 words depending on your project and objectives context. Simply put the context is the background information. Do you have a book that you wanna add? Do you have an article that you wrote that you wanna add to your prompt? Background information that you want to include as part of your prompt? Last but not least the structure. How would you like your output to be structured? Do you want your output to be bullet point format paragraph format or something that you already have in mind? A financial report structure? Any structure or that you want your generative A I to output for you? Once you do that, the next step is you have to feed these input points to an A I model, you feed it to an A I model and you're going to get the response, the response can be some text. The example here can be chad GP T which is a great A I diction native to the next one is images. So if it is in mid journey or any tools out there that provide you with some images, you describe the image and you're going to get a great result. And last but not least you can also get code. Nowadays, we have charge GP T implementation of code interpreters where you can act

### Why Is Prompt Engineering Important?

In this section, we're going to talk about why is prompt engineering important? So let's talk a little bit about the importance of prompt engineering and what are the main variables or the main objectives behind using prompt engineering? Why do we need to use it? One, when we use prompt in a very, very great manner and we engineer them to look clear, amazing, and provide us with the right result, what we have is we improve the results. We save our team, the time for our colleagues, our time, and we improve the results, and we get it directly from the AI tool, which you want. If you know the rules of the game, you can win the game easily. So that's what I want you to understand is that if you use prompt engineering in a very great manner and you follow the best practices, you are going to improve the results. Second one is controlling AI characteristics. Once you understand the documentation of an AI tool and what are the best practices to engineer your prompts, you can easily control AI characteristics and get a great, great output there because you know exactly the length of your article, the dimension of the image that you're going to generate. How many functions automated are you're going to need in order to create a web application? And you know exactly how many you need the AI to provide. So these are good ideas and concepts to keep in mind and put them in front of you any time that you're thinking about, why am I engineering my prompts and making sure that it follows the best practices? Second one is helping with difficult tasks. If you can generate a great prompt and you can write a great prompt, it will be easy for you to conduct any difficult task like regional financial report, building a web app using a prompt, developing data science, perhaps scripts, Python scripts, using a great prompt. So, these tasks are very difficult that need human, perhaps, intuition. But if you engineer the right prompts, you can do them easily without any issues. Next is you get access to advanced functionalities, which are really, really hard to come by. So, once you understand the logic, once you understand the mechanisms of how these prompts work, you can get access to advanced functionality that can also be accessed using normal prompts, then better improved user interaction. So, once you understand these prompts and you know how to work with them, you will feel better working with these AI tools because you're getting the results that you want and you're saving yourself a lot of time. Last, but not least, result relevance. So once you engineer your prompts to get the best result, you are going to get more relevant results, more relevant output, which will make your life much, much easier and save you a lot of time. All right, so these are the main points to keep in mind. So we're talking about improving the results, controlling AI characteristics, helping with difficult tasks, advanced functionality, improving user interactions, and finally, result relevance. All right. Up next, we're going to cover Brief History and Evolution of Prompt Engineering in AI. Stay tuned. It's going to be an amazing section.

### Evolution of Prompt Engineering in AI

Now, it's time to cover a quick Brief History and Evolution of Prompt Engineering in AI. In order to do so, I crafted a very easy diagram that will explain the different stages that got us here, got us into a world where we have generative AI that is creating new content and new innovative ways of doing new daily tasks. So in order to understand this evolution, let's start with the first stage. Stage 1, or what I like to call Early AI, we had a very simple basic AI that takes input. And on the other side, we get some output, for example, a weather predictor. We give the tool a date, and we get the prediction of the weather. Are we going to have a sunny day, rainy day? What kind of day are we getting and what kind of output are we getting? Another example would be a turn rate system, which is simply going to predict if a customer is going to churn or cancel a subscription with a company using a simple predictor. So that's stage 1. Now, let's talk about stage 2, the machinery stage. Thanks to the big data revolution, we found that a lot of this data can be used to train an AI model and to use that AI model to conduct so many amazing tasks such as predicting future sales, predicting the different clusters of customers that visit your website, which one I'm going to buy, which one I'm not going to buy. So we had a lot of innovation and a lot of creative ways. That's where we had deep learning and different neural networks, different very, very advanced AI models that enabled us to have autonomous driving cars and different tools and AI predictive tools that are used in the finance industry, the marketing industry, and also in business. Last, but not least, the third stage is advanced AI stage or the large language model stage. In this stage, we simply create generative AI tools that enable us, thanks to a simple prompt, to craft and come up with new content that was not there before. In other words, we can get a new sentence, a new image, a new sound, a new paragraph that was never created by any human being before just by using a large language model that takes a prompt. And on the other side, it gives us a beautifully well crafted text if we're talking about a text innovative AI model, music if we're talking about a sound generative model, even video if we're talking about a video generative AI model. It all depends on how well you craft your prompt and how well is the tool, that generative tool, that you're using? That was it for our evolution of prompt engineering AI. Up next, we're going to cover prompt design strategies. Stay with me. We're going to have a lot of fun.

## Prompt Design Strategies

### Introduction

Hello, everyone. Thank you so much for joining me again into this module, Prompt Design Strategies. In this module, I'm going to be talking about how can we design an amazing prompt to make your job super easy and save you a lot of time and resources? The module itself will cover the following point. We will start by introduction to prompt design strategies. What are some of the strategies that we're going to be covering? And why are they different? And what can we do to make them even more efficient? Then we're going to compare the different prompt design strategies to make sure that your design strategy fulfills your requirements and saves you some time. Then we'll talk about the explicit instruction demo prompts. So this is where we're going to take one of the strategies, in this case, explicit instructions demo prompt and then add some value by giving you some of the demonstration of how can we add this prompt as one of your toolkits? How can we work with it in order to save you some time and, of course, enable you to easily get the output that you want without any issues? Then question formulation demo prompts. This is a quick demo where we're going to use some amazing question formation techniques to give you the best practices of prompt design strategies and then context setting demo prompts where we put some context and give it to ChatGPT to see if we're going to get an amazing answer. Last, but not least, we're going to cover some tips for effective prompt design. And what are the best practices to get your prompt designed in a great way for your context and your use case? All right. Next, we're going to introduce prompt design strategies and define what are these strategies and how do they differ from each other? Stay tuned. It's going to be an amazing section.

### Introduction to Prompt Design Strategies

Welcome back. In this section, we'll be talking about prompt design strategies, introducing these strategies, and speak about them in a detailed manner. So whenever you hear the definition of the concept of prompt design strategies, it's simply a way to write a prompt, and it shapes the AI model output. So any AI model that you are using, ChatGPT, Midjourney, any tool that you're using out there where generative AI is the main tool, the main technology behind that tool, there is a strategy that you need to follow to save time. The goal here is how can we save you some time using the best design strategies? Each strategy, as you know, will come with a unique set of strengths and weaknesses, strengths and limitations. These strengths and limitations can be very, very different, depending on the context. If you're trying to output an image, you have to understand the limitations of the tool that you are using and the process that you are using. If you're using a text generative tool such as ChatGPT, of course, you will have to understand the different limitations that come with this particular tool and toolkits. Then, of course, we have to effectively use these prompt design strategies to communicate with the AI tool and understand these strategies. So, any one of the tools that we're going to be talking about and mainly the demonstration in this course, which is ChatGPT, we have documentation. If we follow the documentation the right way, we can save time and understand why each strategy is good for us and how can we implement it? So when we talk about strategies, we have to understand that we have different ones. So, using the right strategy will depend on the following variable, the task, so what are we trying to accomplish? Are we trying to generate an article, a book, financial statement or an image that we are going to add to our website? The AI model, what kind of tool are we using in this case? Are we using Midjourney? Are we using ChatGPT? Are we using DALL‑E? What is the tool that we are using? And is this tool going to help us solve the problem that we're trying to solve? And what is the documentation for this particular tool? And of course, the last variable is the desired output. What are we trying to get from the tool itself? Are we trying to get bullet points? Are we trying to get a report? Are we trying to get a long formatted article? Depending on the output, we will have to design a prompt that fulfills the requirement for that output. Up next, we'll be talking about these strategies and comparing them and how can we implement them effectively and efficiently? Stay tuned. It's going to be another wonderful section.

### Comparing Prompt Design Strategies

Now, let's compare the different design strategies that we can use to craft our amazing prompts. When we speak about the diverse design strategies that we can follow in order to create a very easy‑to‑use prompt to benefit us by giving us exactly what we want in terms of objectives and daily tasks, the first option in our design strategies is explicit instructions. In the explicit instructions design strategy, we are simply asking the model explicitly for what we want. Simply put, you can ask the model the following explicit design instruction, provide a list of Python functions. Very simple, very easy. Next is question formulation. In the question formulation design strategy, we are formulating a question to ask the AI model for a simple output. How? What are the main AI models that are available in deep learning? Very simple, very easy. Last, but not least, the context setting strategy that works by providing a context within which the model performs the task. For example, if you are writing a research paper and you want to get some inspirations about the different methodologies used by other researchers, what you can do is take one of your research papers and feed it to the AI model by asking the following question, based on the below research paper, what are the main topics that can be covered in order to advance the research? Now, let's take a look at our story line. The goal is to help you craft amazing, wonderful prompts using the best practice in order to utilize the power and the beauty of generative AI that will enable you to generate text, audio, video, music, you name it that's available in the marketplace. The hero of our story is Sarah. Sarah is an AI hobbyist that's looking to you use AI tools in order to help her company improve its customer support, its customer service to make sure that their clients are happy, their revenue increases, everybody in their customer base is satisfied with their product or services. In order to do that, Sarah is looking to utilize the best practices in prompt engineering and techniques. What I did is I crafted a set of demos that are fun, intuitive, independent, and relatable in order to enable you, no matter what industry you come from, no matter what business you're running or any job that you're taking to use these techniques and create what we call best practices that will unlock the power of generative AI. That's it. Let's go to the next step. Now, let's do a quick demo covering the explicit instruction demo prompt and see how can we implement it using ChatGPT. Once you are logged into your OpenAI ChatGPT profile, which you will see is the following interface, just use the text box available below in order to type in your prompt. The prompt that we're going to be using here is a good demonstration of explicit instructions prompt. The prompt is as follows. It's explicit and to the point. And it reads, "Write a short, persuasive text about benefits of recycling." So we have given the ChatGPT a clear instruction of what we want and how do we want our text to sound in a very easy and direct manner. Then, there we go. So as you can see, we got a response, and we got a title, Recycling: A Catalyst for a Greener Future. So, and then we get our text, "In a world facing unprecedented environmental challenges, recycling stands as a beacon of hope and action." So as you can see here, we are getting a short text, but at the same time, it's persuasive, it brings a lot of arguments to the table to enable us to defend that idea, which is benefits of recycling. So, this is the power of ChatGPT. If you give it an instruction, which is really precise, you're going to get a text that is also very, very precise. Now let's do another scenario. In this scenario, we're giving ChatGPT a direct instruction, "Translate the following English sentence to French." Likely, I speak French, so I can double‑check if it's the correct translation or not. Once you write the prompt, click on the Send message button. "Bonjour, comment ca va?" So as you can see here, the ChatGPT tool executed the instruction that we gave it, which is translating, Hello, how are you? to the French translation, which is, Bonjour, comment ca va? very precisely and very easily. So this was it for our demo. Now, let's go to the second one. For our second demo, we're going to cover question formulation using ChatGPT. And how can we implement this strategy to get the output that we want? So let's jump into the demo right away. Once again, once you are logged into your ChatGPT interface, the first step is to type in your prompt. I already prepared the prompt for us. Our prompt is as follows, "What are the main health benefits of regular exercise?" So we're asking the ChatGPT a direct question using one of the Ws, what, who, where, when? So these are the Ws that we need to remember, so asking the ChatGPT a direct question to get an answer quickly and easily. Once you write the prompt, just click on the Send button. There we go. So we're getting many, many, many benefits in a bullet point format. "Regular exercise offers a wide range of health benefits that impact both physical and mental well‑being. Here are some of the main benefits. 1. Cardiovascular Health, 2. Weight Management, 3. Muscle and Bone Health" ,so on and so forth. So as you can see, we're getting these health benefits in a really compact, amazing manner. So far, so good. Now let's try our second prompt. Our second prompt is as follows, "Why is global warming a major concern?" Click on the Send button, and there we go. We are getting our answer right away. As you can see, the tool itself is very, very fast. So let's start. "Why is global warming a major concern?" "Global warming, which refers to the long‑term increase in earth's average surface temperature due to human activities, is a major concern for several reasons. 1. Climate Change, 2. Rising Sea Levels", and so on and so forth. So as you can see, it's the same format as the question previously or before where we are getting a quick definition of the concept and then some major concerns, in this case, in a bullet point format. So that was it for our question formulation prompt strategy. Now, let's cover the last prompt design strategy, which is context setting demo prompts. So in the context setting strategy, the call itself is to give the ChatGPT some context behind the prompt itself. This context enabled us to limit the knowledge scope of the tool that we are using and give it some context of what we're trying to find. So let's jump in right away. Again, once you are logged into your ChatGPT interface, type in the following prompt, "You are a historian in the 22nd century. Reflect on the impact of climate change in the 21st century." So what we're doing here, we're asking ChatGPT a question and using the second part of the question, which is reflect on the impact of climate change in the 21st century, as the context to get some output using this tool. Once you write your prompt, just click on the Send button. As you can see, we got the clear text that starts with the following, "The 21st century stands as a pivotal era marked by a profound and far‑reaching transformation of the Earth's climate." So, we're getting some context, as you can see here, and we're getting some output. As you can see from the text, we're getting a really, really great response based on the prompt itself. Now let's jump directly to our second prompt. Our second prompt reads as follows, "You are a coach for a basketball team. Provide advice on how to improve free throw shooting." This is so good. This is a really, really great. Why? Because we start with a persona. You are a coach for a basketball team. So far, so good. Then we give the ChatGPT tool subcontext, "Provide advice on how to improve free throw shooting." So far, so good. Let's run it. Wow! So we're getting a very, very, very detailed response, as you can see here. Let's dive in together. "Improving free throw shooting is a crucial aspect of basketball that can make a significant difference in the game outcomes." So we are getting some context. which is really, really great. And then we get the follows, "Here's a comprehensive set of advice to help your players enhance their free throw shooting skills." And we're getting these bullet points, Fundamental Technique, Mental Preparation, Physical Conditioning, Repetition and Practice. So we're getting really great advice here just by giving the ChatGPT tool some context and the goal of what you're trying to do. That was it for our demo. Let's jump into the next section. Up next, we're going to cover Tips for Effective Prompt Design. Stay tuned. We have some amazing tips for you.

### Tips for Effective Prompt Design

Tips for Effective Prompt Design. In this section, we're going to talk about the different tips and tricks to create an effective prompt to get your best output. We'll start. To effectively write an amazing prompt, we have to follow the following tips. One, ensure your prompt clearly communicates the task. So the goal here is clarity. Make sure that everything is clear, everything makes sense, everything is direct without any ambiguity to save time and get the output that you want because at the end of the day, we're dealing with computers here. We are dealing with an AI model, so less words mean more quality, and precision means good outcome. Okay, next. Be as explicit as possible to prevent confusion. So the goal here is make sure that the idea or the prompt itself is clear. To get a great output without any confusion, keep prompts concise and to the point. So the next tip is making sure that the prompt itself is concise and to the point, which means any additional words that will not add more value to the prompt itself, make sure to remove them to get a wonderful, strong prompt so you get an amazing output that you can use in your daily task. Next, avoid unnecessary details that could distract the model. Don't forget, the model at the end of the day is an AI tool. So any additional words can create a distraction that will give you a bad output. So the goal here, how can we avoid unnecessary details that we don't need? In case you're looking for a definition, for example, write definition for machine learning. So this is a concise direct prompt. If you write it like this, it's going to be an issue, write a definition for machine learning. Don't avoid to also define machine learning a second time. So we are confusing the model because we're adding unnecessary details that are not really helpful. The call is to get the definition of machine learning. So we just ask the model to write a quick, easy definition of machine learning. All right. Last, but not least, don't hesitate to tweak and test different prompt strategies. So at the end of the day, I shared with you these strategies because I want you to test all of them. So you can start with the context setting strategy, then switch to question formulation. And if none of them give you the output that you need, you can always go back to the explicit dialect questionnaire where you are asking the AI tool a direct context‑based model, or you can combine all of them. So the goal here is you can always test all of them, tweak your prompt to get the output and to get the answer that you need. All right. Up next, we're going to cover prompting methods. Stay tuned. We have a wonderful module coming up next.

## Prompting Methods

### Introduction

Hello, everyone. Welcome to another module. In this module, we're going to cover prompting methods, and we're going to be talking about how can we use these methods to facilitate and make our prompt engineering process easy and quick? So, in this module, we're going to cover the following point. We're going to start with a quick introduction of prompting by instruction, which is one of the main pillars, one of the main building blocks of prompt engineering. So how does it work and what are the main variables that this method takes under consideration? And we'll be speaking about prompting by example by showing you some of the examples that are used in this particular method. How does it work and how can we implement it in our prompt engineering tasks? Last, but not least, we're going to talk about the pros and cons of different prompting methods and what are the different, perhaps, advantages and disadvantages of each one of the methods that we're going to be covering in this module. Up next, we're going to cover prompting by instruction. Stay tuned. We're going to have an amazing section.

### Prompting by Instruction

So what is prompting by instruction? If we think about prompting by instruction, I created a very easy, clear definition to keep it very intuitive. Prompting by instruction gives explicit, clear directives to an AI model to guide its output. So the goal here is clarity, clarity, clarity. Make sure that our prompt is very clear so when we feed it or give it to the AI model, we get amazing results at the end of the day. So let's take a look at perhaps prompting by instruction using a very simplified easy‑to‑understand diagram. We start with our input. So the starting point of any AI model that is used in generative AI is the prompt. And in the prompt, you have some input. Your input should contain the following attributes, direct commands, so it should be very direct, define machine learning, define computer find, define program, define financial methods. So, make sure that the, perhaps, prompt itself is very, very, very direct to avoid any issues and confusion and eliminate all the ambiguity while creating that prompt. The second attribute is guiding responses. Guiding responses means simply by providing in you prompt some guidance to help the AI model duplicate the response that you want. Let's say you are in a company and the way that you write proposals is very unique to your organization. So you have to provide the AI model with a quick template, if you will a quick input. So you guide the AI model in providing you with the best output based on your style and template. The third attribute is precision matters. So at the end of the day, you have to be very precise. So, less words here is very important in creating that sentence, that prompt that you're going to give to the AI model. So avoid any additional words that are going to create an ambiguous response by your AI model. Once all of these attributes are put together into a wonderfully well‑crafted prompt, the next step is we have to feed it to give it to the AI model. And no matter what AI model we're going to get, that is Midjourney, ChatGPT, any one of those very popular AI models in the marketplace is going to give you an output. So, keep in mind this diagram while working with this method, which has prompted my instructions, keep your responses and your prompts direct, use guiding responses, and finally, precision matters. Now it's time to jump in a quick, very easy‑to‑understand demonstration of prompting by instruction, so let's do this. Once you are logged in in your profile, what I want you to do is type in the following prompt, "Create a bullet point list of the steps to bake a cake." So it's a very intuitive prompt. So what we're trying to do is we're trying to get a step‑by‑step approach of how to bake a cake. For example, you are running a blog or a website where you're helping a lot of food lovers create and innovate in the food creation process. So you're asking ChatGPT for that response. Once you type in that following prompt, just type in Enter button. There we go. We're going to get a very easy intuitive step‑by‑step approach of how we can bake a cake. So we have first initial step, which is gather the ingredients, then preheat the oven, prepare the cake pans, and so on and so forth. So we have all of these steps that are written in a very, very easy manner. These steps can be used to create your own blog post, to create social media posts, etc. easily without an issue. So, what I want to take your attention to is the format of the prompt. So create a bullet point list. So we are direct, we're precise, and we know exactly what we want. To do what? Of the steps to bake a cake. So this is perhaps a very, very good example of direct prompting in a very easy way to demonstrate prompting by instructions. Now let's do a second example. For our simple example, we're going to use the following prompt, "Design a simple workout routine for beginners." So the goal here is we are running our website for workout professionals or for people who are searching for a new workout, a new habit in their daily lives. And what we would like to do is to create a quick guide for them to share with them via a PDF file, if we want. So how can we do it? Design a simple workout routine for beginners. So, just quick, easy to understand. The prompting itself is very, very intuitive and direct because we're using the prompting by instruction method. So we are asking the AI tool to design a simple workout routine for beginners. So, it's not going to be very advanced, so it's for the beginners. Simple. So it should be easy without choosing any perhaps complex strategies. And we are developing a workout routine. So once we do that, click on the Enter button. There we go. Wow! So we are getting a really, really comprehensive text. So, we start with a big paragraph in the beginning, and then we have warm‑up and then the workout. And in the workout, as you can see here, we have a step‑by‑step approach, as you can see, then there is a cool‑down and then we have notes. So this is very professional, as you can see. We have the intro, we have the warm‑up, the workout, and finally, cool‑down and notes. So, that was it for the demonstration of our prompting by instruction. Up next, we're going to be covering prompting by example, another amazing prompt engineering method. Stay tuned for the next section.

### Prompting by Example

Now, let's cover prompting by example and speak about this method in a very easy manner. Prompting by example is a simple prompting engineering method where we are teaching the AI model a technique to provide specific examples for the tools to get the desired input/output pairs. So the goal here is we're showing, we're providing the AI model with an example of what we want. And then we are letting the AI model do the magic and give us output. So let's take a look at the diagram that will simplify this method. So, as you know, we start with a quick input box where we type in our prompt. If you want your prompt to follow prompting by example, it should follow the following attributes. One, teach by example, so provide the AI model an example. Write an article that follows the same template as you can find below. So, provide the AI model with the template and let it do the work. Second one, contextual learning. So by providing the AI model with the context, you are eliminating all the ambiguity and limiting the scope of knowledge for the AI model so you know exactly where you're getting your information. Let's say you have an academic article and you want to just get some information from that article. You can just provide the AI model that article and get the information just based on the article. Based on the following academic article limits your definition of AI to below. Then you provide the AI model with the academic article. So, these combinations are very, very, very powerful. Third, quantity and variety. So the goal here is we have to make sure that the context that we are provided or the example that we are provided enables the AI model to learn, enables it to know exactly what's the goal from your input and output. And, of course, variety, we have to show the AI model different articles, different perhaps pairs of input/output. So, the model will learn what is the objective or the goal that we are trying to satisfy using the input and that we want to get using the output. Once we follow all these attributes, the next step is to take all these attributes and give them to an AI model, which will result at the end of the day into a wonderful output that satisfies our need based on prompting by example strategy. Now, let's dive in into a quick demonstration to showcase the power of prompting by example. Once you have access to the ChatGPT interface, type in the following prompts, English: "Hello, how are you?" Spanish: "Hola, como estas?" English: "Good morning." Spanish: empty. So what did we do here? We provided the AI tool, the AI model ChatGPT with very easy English/Spanish pairs. We were providing the AI model with the English sentence, and then following that English sentence is a Spanish sentence. And then we did the same the second time to see if the AI model will understand that we're trying to translate from English to Spanish. Once you write the prompt, just click on the button Enter. Wow! So we are getting the response, "Buenos dias!" So as you can see here, the AI model is doing a really, really great job by providing us with the exact response that we want and doing the work by translating the input for us based on the examples that we provided. So this can be expanded to any other languages to any other tasks easily without any issues. Let's try another example. All right, for our second example, we are going to use the following prompt, Text: 'AI is advancing rapidly.' Tone: Neutral. Text: 'This is the best day ever!' Tone: empty. So we are trying to ask the AI ChatGPT to give us the tone of the sentence based on the initial example. Let's see how well it would perform this task. Text: 'This is the best day ever!' Tone: Positive/excited. So it's doing a lot of the work, the heavy lifting itself. And this is a subfield perhaps in AI that is called sentiment and analysis. We are taking a sentence and providing the sentiment of that sentence. Let's try another example to make sure that we get the concept. For our third example, we are using the following prompt, Statement: 'It's raining outside.' Question: 'Is it raining outside?' Statement: 'The cake is delicious.' Question: empty. So we are trying to teach the AI model the action, if you will, or the process of taking a sentence and building a question based on that sentence. Let's see how it would perform. "Is the cake delicious?" So as you can see here, we are getting amazing results in the task that provided the AI model where we are getting the translation done easily, the sentimental analysis tasks easily, and, of course, question creation task easily without any issues. And that is very, very powerful because we are enabling the AI model to use the example of tasks that we want without even mentioning what task we want. And the AI model understands exactly what we want without wasting a minute. Now, let's continue with our section. Up next, we're going to cover the pros and cons of different prompting methods. Stay tuned, and see you in the next section.

### Pros and Cons of Different Prompting Methods

In this section, we're going to cover the pros and cons of different prompting methods. Let's take a look at these methods. We start with the pros and cons of prompting by instruction, which is the process of creating a prompt that is direct, clear, and precise. Let's look at the pros. So for the pros, we have offers precise control over AI behavior. We know what we want, we know how to ask the question, and we are getting exactly what we want. So we have precise control of the AI model that we are using. Ideal for tasks with specific expected outcomes. So, it's really, really good for definitions, for financial analysis, for tasks that we know exactly what we want to get. So the definition, we know exactly the definition that we want to get. Let's say we are doing some calculations on financial models, we know exactly what kind of numbers we're going to get. So it's really good for outcomes that are expected and specific. Requires less setup compared to prompting by example. So, because we are using prompting by instruction method, we don't need an example. We can just ask the AI model to do the work for us without giving it any examples. Now let's look at the other side, the cons. We looked at the pros. Now let's look at the cons or the disadvantages. So, the first one will be requires clear and unambiguous language. So we have to make sure that if we're asking the AI model for a task, it's clear, it's easy to understand, and it's very, very precise. So, anything ambiguous can create a bad outcome and a bad output for us. Second one is may struggle with complex or nuanced tasks. So, if we are doing a very, very complex task such as data analysis or we're trying to get the understanding of a very complex philosophical idea without having an example, we might have some issues with the output. So, it doesn't work with complex tasks or with tasks where we need an example. Last, but not least, the model interpretation may not align with the user intent. So the goal here, if we have an example in mind, it's better to use prompting by example instead of trying prompting by instruction because it is more of a definition and action, a precise task method. And for this case, without having to use an example or without using an example, we might face an issue of not having a clear output. Now, let's take a look at the pros and cons of prompting by example. So let's start with the pros. It's really effective for handling complex tasks or those requiring creativity. So we are building a financial statement. We are creating an article that follows a specific template. We are developing a creative book that follows a very specific pattern. And we have an example, we have a template. Those are creative tasks that need an example, and that's why prompting by example is super great for those particular tasks. Demonstrates the desired output, reducing ambiguity. Once we demonstrate the desired output, once we show the model what kind of output we want, we're going to reduce the ambiguity because we already have an example of what we want. And the AI model will just follow based on the example. Enables the model to learn from a variety of scenarios. So, the good here is the variety. So we are giving the AI model some different scenarios. These scenarios are going to be used as training data for the language model or the model that we are using or any type of model. And then that data will be used. Let's train the model and show the model an example, you know what? This is the output that I want. This is the article model that I want. This is the book that I want. So you know exactly what kind of example you're showcasing the AI model, and you are avoiding all the ambiguity by making it simple and precise and providing a great example. Now let's take a look at the disadvantages. So, it requires numerous high quality examples for training. So the goal here is you have to provide two variables, quality and variety. So you have to provide quality examples here to the model, and they should be very, very perhaps multidimensional, so they provide a different aspect of your example. So if you're building an article and that article is intended for technical users, for finance users, for marketing users, for daily readers, so you have to provide your AI model these types of articles to show the model that the tonality of your article, the structure of your article is different based on the user and the intended outcome. Next, the model may become too fixated on the given example. So this is a very, very big problem because once you provide the model with the examples, if they don't vary, if they are not multidimensional, that example will be the standard, which means the model won't be creative enough to create something new. So, you may face this issue. That's why quality and variety is very important. Last, but not least, time‑consuming and resource‑intensive to collect and prepare examples. So you have to do some prep, and you have to do some work before you start asking the AI model for these outputs. So it's going to be very, very complicated and time‑consuming to create this example and make sure that they are multidimensional, that they vary between different categories and selections. So that's something to keep in mind. Up next, we're going to talk about controlling model output with prompts. Stay tuned. You have an amazing module waiting for you.

## Controlling Model Output with Prompts

### Introduction

Hello, everyone. Welcome to another module of our course. In this module, we're going to cover Controlling Model Output with Prompts. In this module, our goal is to have a great idea of how do we control the tonality and the level of details in your output using specific prompts. The main subsections of this module will be covered as follows. We will start with a quick, basic introduction of output control mechanism through prompts. So how to we control the length of your texts and also the tonality and what are some basic mechanics that we can put together in order to control the output from A to Z? Then, we're going to cover techniques for controlling verbosity. That means we control the detail, the level of details of your output. If you want to get a long, let's say, paragraph or report or article or you want to get a quick introduction abstract for an academic paper, depending on your needs and use case. Last, but not least, we're going to talk about controlling the tonality. Do you want a friendly paragraph, a friendly text, a friendly output, or are you looking for something that is different, formal, academic, finance industry‑based? What is the specific output that you're looking to output using your prompt and using prompt engineering? So stay tuned. We have an amazing section coming up, which is Basics of Output Control through Prompts. See you in the next section.

### Basics of Output Control through Prompts

In this section, we're going to cover the Basics of Output Control through Prompts. So mainly the idea here is what are the mechanisms that we're going to use to control your output using some amazing best practices of prompt engineering. We'll start with a quick understanding of output control through prompts, so what it is and what do we mean by it? Honestly speaking, controlling the output of an AI model is known as output control. So any time that you are controlling the output, that is outputting an image, outputting a sound, outputting a text, this all falls under the subfield of output control. Second, consider content, context, format, length, style, and tone. So these are the attributes of control output. So any time that you hit control output or output control, you have to put in your mind that we're mainly speaking about the content, the context, the format of your text, the length, the style of writing, and also the tonality. Then, any time that we speak about control of output, we're always trying to understand it. Better output control improves AI's ability to personalize the responses. So if you have a good understanding of how can you use prompt engineering to better control the output, the output that you're going to get is going to be phenomenal because you have an understanding of what it is to control the output and get the exact output that you want, depending on the use case. Because if you're writing an article for a blog, for normal readers, it's going to be very different from academic papers or even something that is more formal for your workplace. Last, but not least, understand the model's prompt types for efficient output control. So any time that you are using a tool, it's very important to read the documentation and understand how do we write prompts that are going to provide the best outcome, the best output for our use case? If you're using ChatGPT, there is documentation for ChatGPT. If you're using Midourney to get some images, there's also some documentation to get the best output from Midjourney and control your outcome. All right, up next, we're going to cover techniques for controlling verbosity and tone of the output. Stay tuned. We have a great section coming up.

### Techniques for Controlling Verbosity and Tone of the Output

Now, let's cover techniques for controlling verbosity and tone of the output. So we start with a quick, easy definition. What is controlling verbosity? Controlling verbosity is the process of managing how much the model outputs and how detailed it is. So the goal here is, do you want a very detailed piece of text or do you want something short, something compromised, something that is perhaps compressed, if you will, something that is summarized? That's verbosity. Anytime that you hear this keyword verbosity in the output control mechanisms or field, you have to understand that we're trying to determine how detailed the output that we want is. And of course, this will depend on your use case and the task that you are performing using ChatGPT. You can direct the model using specific prompts to give you a short summarized paragraph or an in‑depth explanation of a concept. So if you write to ChatGPT define machine learning in a very small paragraph, it's very different from define machine learning in a 2,500‑word article. So those are some of the considerations or attributes that you have to put in your mind while working with ChatGPT, and those are very important to understand exactly the length and the level of details of your chatbot or the tool that you are using. Next, we have to cover controlling the tone. So anytime that we speak about the tone, we speak about the way or the manner the text is written. Is it user‑friendly? Is it formal? Is it academic? Is it intended for finance readers, for marketing readers, for engineers, for day‑to‑day business users? So depending on your audience, the tone will be very, very, very, very, very different. And that's something that we can control using ChatGPT. By directing the style and mode of your AI response, this can create a great output for you. Because if the output that you're working with is the same and it's very, very, very basic, you're not going to engage the reader, and that's not the objective of using an AI tool. Using an AI tool should allow us as human beings to get a great response that can be used in our daily life. So, keep this in mind working with ChatGPT, and I have some amazing techniques, best practices I'm going to share with you. Using these techniques, you can achieve a very, very well specified desired tone in your prompt. All right. So these are the two main amazing points, and they are really, really important, so mastering verbosity and tone control. So if we talk about verbosity and tone control, we have to understand these two parameters. So what is verbosity and what is tone control? Controlling the verbosity, we can use the following starting points, in one word, in one sentence, in a paragraph, briefly explain, provide a detailed analysis. So this is really good because in one word we are specifying that we just need one word that perhaps explains the concept of AI. Very nice. In one sentence, define computer science, in a paragraph, speak about the art of programming, briefly explain the power of artificial intelligence, provide a detailed analysis of the stock market in 2020 of Microsoft stock. So these are some of the great ones that you can use, and the beginning is always very important. Now let's take a look at controlling the tone of your output. We can do that using the following keywords, formal, casual, humorous, as if explaining to a child, like you're talking to a friend. So adding these keywords, adding these statements can be a great modifier for your output controls because you're enabling the tool, the AI tool that you're using, in this case Chat GPT, to provide you with an output that can be formal, casual. If the concept is, let's stay, very, very difficult, define quantum computing as if explaining the concept to a child. So you can mix things up to create a very, very, very useful output for you like you're talking to a friend. There's something also that you can add, explain the financial statement of Microsoft in 2020 like if you're talking to a friend. So these are some of the great combinations that we can use in order to provide amazing controlling of the tone of your output. So now we saw the difference between controlling verbosity and tone. Let's dive directly to a quick demo to provide you some amazing tips and techniques for verbosity and tone control. Stay tuned. Let's dive right to it. Once you are ready and logged into your ChatGPT interface, start with the following prompt. We will start with a quick prompt to demonstrate verbosity control, "Give me a one‑sentence overview of the impact of deforestation." Very easy with asking the tool to provide a one‑sentence overview. Let's try it. We get the following output, "Deforestation leads to the loss of vital ecosystem, biodiversity, and carbon storage." So as you can see here, we get a very, very good sentence that is detailed. And at the same time, we get the overview of the impact of deforestation, and we have great verbosity control. Now let's show another example. Now let's take a look at our second prompt, "Give me an extensive report on the impact of deforestation." Let's do a very quick comparison between the output of the first one and this one. I'm just going to click on the Enter button. Wow! So as you can see, we're getting a title, abstract, introductions, and then we have many, many, many paragraphs. So I'm just going to scroll up so we can see together. To start, we have a title, the title of our extensive report, we have an abstract. So this is a very, very well‑written report. We have an introduction, we have a subsection, the first one, second one, third one, and finally, we have a conclusion. So there is a big, big, big difference between the first prompt where we get one sentence and the second one when we get a long, very extensive detailed report. So this is how we can control verbosity. Now let's take a look at how we can control the tone of your output. To control the tone of your output, you can use the following prompt, "Provide a formal introduction to the concept of machine learning." So the keyword here is formal just like I showed you in the table that we covered previously. So formal is the keyword that provides your AI model with some context that you want something that is very formal. I am going to click on the Enter button to see the output. Wow! So we are getting very, very, very formal content, as you can see here, and it starts with an introduction. So introduction to machine learning, then we have a paragraph, "Machine learning is a subfield of artificial intelligence(AI) that focuses on the development of algorithms and models that enable computers to learn from and make predictions or decisions based on data." So as you can see here, very, very formal, extremely strict, and very very, it's like academic content that we can share and we can also use in our daily life. So very nice. We have the main types of machine learning, so supervised learning, unsupervised learning, and reinforcement learning. And we are getting more details and, of course, a conclusion at the end. So this prompt, as you can see here, was very successful at providing us with a formal introduction to the concept. Now, let's try another one that is perhaps more human‑friendly, "Explain machine learning like you're talking to a friend." So the second prompt is very strict, very straightforward. What we're trying to do is we're trying to make it more user‑friendly, more human‑friendly. So, talking to a friend, which means if you're talking to a friend, you're not going to use formal words. You're just going to speak in a way to explain to somebody who doesn't understand perhaps the concept, and it's going to be a very, very normal conversation. So let's try this prompt together. Wow! So it's already giving us some amazing output. "Hey, there. So, you know how computers are really good at following instructions?" This is a question. "Well, imagine if we could teach them to learn from examples instead of telling them exactly what to do. That's basically what machine learning is all about!" So this is a very good, perhaps, introduction or initialization of a conversation with a friend. So, hey, there. You're talking to a friend, so it's a very, very friendly conversation. Then you have a question, so you are starting a conversation. So, we just note the difference between a very formal report and something that is more human‑friendly that you can share in social media. Up next, we're going to cover, in the next module, reducing repetition, which is a big problem in AI output using some great best practices in prompt engineering. Stay tuned, and see you in the next one.

## Reducing Repetition in Outputs

### Introduction

Hello, everyone. Welcome back. We are going to cover a very necessary, but easy‑to‑implement technique called reducing repetition in outputs. While dealing with AI models, one of the main issues we face is repetitive outputs in your text, and we're going to cover how to fix it. In this module, we're going to cover the following points. What is repetition in AI outputs and how do we determine it? What are the best techniques to minimize repetition in AI outputs? How can we tweak our prompts to avoid repetition in our outputs? And what is the best way to conduct a technique called post processing your prompts? Last, but not least, what is upsizing the model and how can it help us in reducing repetition in our AI outputs? Up next, we're going to cover Understanding the Repetition Problem in AI Outputs. Stay tuned. We're going to have a lot of fun.

### Understanding the Repetition Problem in AI Outputs

Now, let's cover Understanding the Repetition Problem in AI Outputs. Whenever we talk about repetition in AI outputs, we have to understand the following statements. One, AI is going to repeat and generate similar content if you don't give it the right prompt. So this is a very, very easy, perhaps, fact to keep in mind. If we don't have the right output, if we don't follow the best practices, repetition is going to happen no matter what because we are not creating something new, we are not developing a new prompt that is going to reduce that repetition problem and give us a great output. The second point is the causes of this repetition can include many, many issues. One of which is data, the model, even the prompt that you are provided. So, if we see a repetition pattern that is happening in any one of the AI generative models that we are using in today's world, we have to understand that removing them is a byproduct of fixing the data, the model or the prompt. Last, but not least, finding the root cause is key to solving any problem, especially when we deal with output repetition in AI. So we have to understand, are we facing this issue because of the data, we're not giving the AI model more context? Is the model not doing a really good job and we need to update it or upgrade it? And finally, the prompt, which is something that you're going to deal with in this module. Now, let's take a look at repetition in text generative AI using a very simple diagram as a visual representation. We start with an input prompt. The input prompt should contain two main variables, the text, which is the prompt, and the context. For example, define artificial intelligence using the below article. And the article is going to be the context in this case. So once we have an input prompt, we give it to the AI model. We're going to get an output. And inside that output, we notice some sentences that are repetitive, some sentences that are paraphrased. At the end of the day, we want uniqueness, we want something that is unique and pure. In order to get that answer, we have to understand the issues. Is the issue with the article? So the training data, the data, the context that we are giving the prompt is not that unique by itself, so we have to change the context. So if the article is not good enough, it's not very well written or it contains repetition by definition, we have to change the context. Second, modern architecture. So if the model that we are using is not good enough, we have to change the tool that we are using. We have to upsize the model, we have to upgrade the models we have to fix it by changing the model to get a better article. Last, but not least, prompt variability. So we have to make sure to change our prompt to make sure that we are fixing this issue by changing the way that we ask the AI model for the output or the way that we construct that prompt while giving it to the AI model. All right. Next, we're going to cover strategies to reduce repetition. Stay tuned. We have a great section coming up.

### Strategies to Reduce Repetition

Now, we're going to cover strategies to reduce repetition using prompt engineering. So what are some of the tactics, some of the tips and tricks that we can use in order to reduce repetition in your prompt engineering process? First, we can tweak the prompt. So tweaking prompt is a very, very common technique by modifying the original prompt to avoid repetition, making sure that we eliminate any unnecessary words from that prompt and making it clear and easy for the AI model to understand. Two, post‑processing. So post‑processing is a step where we give the AI model a prompt, define machine learning, then we ask the prompt itself or the AI model itself another time to remove any repetition from the above definition to get another answer, and that's post‑processing. Last, but not least, upsizing the model. So the way that we upsize the model is by using a larger model. So if you are using ChatGPT 3.5, what we can do is upgrade to 4. If we are using a tool that does not benefit us, that does not provide us with the right text that we want, we can just find another text that uses a larger dataset or a bigger language model that can help us eliminate any repetition. Now, it's time for a quick demonstration to show you how we can use this technique in order to eliminate all these reduced repetition problems. Stay tuned. We have a great demo coming up. Once you are logged into your ChatGPT interface, the first step is to type in the following prompt to demonstrate how we can reduce output repetition in your AI model. So let's pretend that we are a book‑writing company, and our job is we're writing books that speak about stories, and we're helping people understand technology using stories. How can we do that? We start with the following prompt, "Write a story about a rabbit in a forest." We type it, then we click on the Enter button. Now, as you can see, we are getting a story. It contains characters. It contains many, many, many paragraphs. As you can see, we start with a typical storytelling format, "Once upon a time", and then we get the story as follows. 100%, this story contains some repetition, some paraphrasing, and we have so many things that are repetitive. In order to fix that and make sure that we don't get any repetition, what we can do is write the following prompt, "Write a story about a rabbit in a forest, but don't repeat any sentences." So by adding this statement at the end of our sentence, we are forcing the AI model, we are pushing the AI model to avoid any repetition. We might get less text, but at the end of the day, it is unique and great for our purpose. Click on the Enter button to test. There we go. So, we are getting perhaps a shorter text, but it contains less repetition, and that's the goal that we want. Now let's test another technique, which is post processing. Now we can type in the following prompt, "Tell me about the health benefits of drinking water." Once we write it, we can just click on the Enter button. As you can see, we are getting so many bullet points. "Drinking water is essential for maintaining good health as it plays a vital role in various bodily functions. Here are some of the key health benefits of drinking water:". And we're getting some bullet points, as you can clearly see. Now, this text itself will contain so many repetitions, so many health benefits that are written in another format. In order to eliminate the repetition, what we need to do is to ask the ChatGPT for a shorter, less repetitive answer, so let's do that. Just type in Shorter, less repetitive, Shorter, less repetitive in the text box, and you're going to see a big transformation. Click on the Enter button. Wow! So we are getting a more condensed, shorter text with all the bullet points that are speaking and covering drinking water health benefits. So, it's much, much better than having a text that is repetitive and doesn't provide any value to the end user. If you don't like what you see, you can also do it another time. So the post‑processing method works by tweaking again, and again, and again until you get exactly what you want. So now we're going to get an even shorter input, and we're getting the health benefits of drinking water in very easy sentences that can be followed and can be covered without any issues. Now let's take a look at upsizing our AI model to fix and cover the issue of repetition to showcase the power of upsizing your AI model as a tool to reduce repetition. What I did is I created a side‑by‑side comparison of the ChatGPT model 3.5 and the ChatGPT model 4 or GPT 4. This be the difference in terms of repetition and quality of text and showcase the power of upsizing your model as a way to avoid repetition in your output. So I will run the first one. By clicking on the Enter button, the prompt was as follows, "Describe the importance of preserving biodiversity." So as you can see here, we're getting a quick definition of biodiversity, and then we're getting some bullet points describing the importance of biodiversity. Let's run the same prompt in the GPT 4 model size. (Working) Wow! So we are getting a really, really good, very, very nice text in the second model as well. But it's more condensed, smaller, shorter, less repetitive, more value, and that's simply because we are upsizing. We're using a better model, if you will, a better implementation of the language model here, which is GPT 4. And that's how we can easily fix the repetition issue just by using my computational power or a better model, in this case. Awesome! So that was it. Thank you so much for your time. I really appreciate it. See you soon in the next section. Up next, we're going to cover designing prompts for different tasks and how can we use prompt engineering for various day‑to‑day tasks? See you in the next one.

## Designing Prompts for Different Tasks

### Introduction

Hello, everyone. Welcome back to another module of our course. In the module today, we're going to cover Designing Prompts for Different Tasks. The idea here is specificity of the task using prompt engineering best practices. So let's take a look at some of the main submodules or sections that we're going to cover in this one. We'll start with a very, very easy customizing prompt for various tasks. So how do we customize prompts for different and various tasks? Then, we move to task‑specific prompt design. So what are the design strategies that we can follow in order to make sure that we fulfill the requirements of every task that we have on a daily basis? Last, but not least, the importance of task‑specific prompt design. Why are they important to us and how can we leverage them for efficiency and creating a quick resource for our daily tasks? So now, let's jump into the next section, which is Customizing Prompts for Various Tasks. See you in the next one. It's going to be a wonderful experience.

### Customizing Prompts for Various Tasks

In this section, we're going to cover Customizing Prompts for Various Tasks and see the magic behind this amazing technique. We start with a very, very simple introduction of what are some of the tasks that we can cover using prompt engineering best practices. We can easily summarize our text. If you have a text, an article, a book, an academic paper, a financial report and you want to summarize it, you want to just see the main bullet points from that specific financial statement, you can ask the tool, ChatGPT, or any other tool out there in the market space to summarize that text for you and get the main bullet points, the core idea of that specific content. You can also use this prompt engineering technique for question answering by answering some of your questions that you have and making your learning process much, much easier and faster. You can conduct sentiment analysis, which is a very, very powerful technique that enables you to take any sentence, text, paragraph and define what is the sentiment behind that specific text. This can be really useful for brand recognition, so if you have a company or you want to understand how your customers are perceiving a product or service that you are just starting to launch in the marketplace, you can gather the information from social media and analyze to understand the sentiment of your users, if they're happy with the product or service or if the product needs some more translation tasks or if you are exploring a new language or if you have product description from various e‑commerce stores and you want to cover many, many languages, you can use this prompt for your translation tasks. Named entity recognition is a very, very powerful feature that enables you to take different names or keywords and recognize what they are. Are they companies? Are they cars? Are they softwares? What is the following entities or the following recognized entities inside the paragraph, an article or a sentence? And this is a great, great definition that we're going to cover in the demo as well. Last, but not least, creative writing where we can create very interested samples that can be used or very creative tasks such as social media marketing, creating a very well documented script or your YouTube video. Anything that takes creativity, it can be accomplished using the prompts that we're going to cover. Now let's do a quick demonstration of this test. And in the demonstration, we're going to cover the following task. We will start with the summarization demo where we're going to take a text and try to summarize it using a very creative prompt. Then we're going to cover sentiment analysis. So we have some text, and we're going to define what is the sentiment behind that given text. Last, but not least, we're going to cover named entity recognition prompts that are going going to be useful to label some of your text content, especially if you have a large dataset that you're going to use. This is very, very useful for our case study. Especially as a customer support agent, you will definitely need to analyze some text that you're going to get from your customers. And you know that you have to start with some of the labels, the issues, and entities that are available in the text. Now, let's jump right to it. Once you are logged in to your ChatGPT profile, enter the following prompt that will demonstrate how we can use summarization techniques using prompt engineering. Summarize the following paragraph, "The internet is a vast network that connects computers worldwide through the internet, people can share information and communicate from anywhere with an internet connection. Rapid advance in technology over the past few decades have made the internet an essential part of our daily lives." So let's see if ChatGPT can summarize this paragraph in a very easy manner. Click on the Enter button. Wow! So we get a very, very clear summarization of our paragraph that is as follows, "The internet is a global network linking computers across the world, enabling information sharing and communication regardless of location. Technological progress has integrated the internet into our daily routines." So the core idea is there, and we just summarized it and made it very, very short. All right. Now, let's discover the usage of sentiment analysis prompt using ChatGPT. Write the following prompt, "Analyze the sentiment of the following sentence, 'I had a wonderful time at the park, the weather was fantastic and the people were friendly.' Click on the Enter button. Wow! So we get already the results, and I want you to really focus on the last paragraph. Overall, the sentence conveys a sense of enjoyment, satisfaction, and positivity about the experience at the park. So the tool itself, our engine itself provides us with a very, very clear explanation of the sentiment and explains wherever you were in the sentence itself. What are the keywords that are positive, negative or not sure? Very, very powerful tool. Now let's move on to named entity recognition prompts. Now, let's run a prompt that will help us to identify some entities inside the sentence. Let me show you an example, "Identify the named entities in the following sentence: 'Steve Jobs and Steve Wozniak founded Apple Inc. in Cupertino, California.'" So we have a sentence that speaks about the founders of Apple. It also provides us with the name of the company and the location of the company. So let's run it. Wow! So we got a very, very clear output that provides us with the following output. So we have Steve Jobs (Person), Steve Wozniak (Person), Apple Inc. (Organization), Cupertino (Location), California (Location). That was so impressive, and we can do this for any paragraph, article, books, you name it, ChatGPT can do it. All right, up next, we are going to cover the Importance of Task‑specific Prompt Design.

### Importance of Task Specific Prompt Design

Now, let's speak about the Importance of Task‑specific Prompt Design. Once you start implementing and understanding the process of writing great prompts for your tasks, you will gain the following amazing byproduct of that specific design, greater accuracy. Initially speaking, any time that you know exactly what you want to do, sentiment analysis, you have a text that you want to summarize, you want to recognize some entities inside a paragraph. Once you know the task at hand, you will have greater accuracy. So task‑specific prompts help set a clear context for the AI model, leading to more precise outputs aligned with the desired outcome. So this is such an amazing byproduct of having a specific idea of what kind of tasks are we trying to conduct. Next, fine‑tuned control. So what do I mean by that? We can shape the output's tone easily once we understand what kind of task that we're trying to do? Are we trying to write an article? Okay, the article is designed for a friendly audience. Now we understand what kind of style format to tailor and to write the prompt for that specific audience. Next, improved performance. So once we understand what kind of task that we're trying to do and we craft and design a prompt for that specific task, we can easily enhance the model's performance in creating a very, very effective output across all our tasks. Last, but not least, better user experience. So once we know exactly what kind of tasks that we want to create, we can have a better user experience because of the high quality of the responses that we are going to get. Up next, we're going to cover the conclusion of our course. Thank you so much for the time. See you in the next one.

## Conclusion

### Conclusion

Welcome back. This is the conclusion of our course. In this course, we covered so many great modules. We started with a quick module that introduced prompt engineering by giving it a quick definition and covering some ground of what is prompt engineering and what makes this new concept very interesting to learn. Then we spoke about prompt design strategies and what are the different strategies and best practices that we need to follow in order to build a powerful prompt to get the output that you want. We also covered prompting methods, and we took a look at the different prompting methods and the advantages and disadvantages of each one of the methods that we talked about. We also controlled the model output and showcased some of the prompts used to reduce the number of characters in your prompt and control the amount of text or output that you get using AI generative tools. We also spoke about the issue of reducing repetition and what are the best practices to avoid this issue. Last, but not least, we spoke about designing prompts for different strategies, and we demonstrated some of these strategies in our demo. If you want to learn more about prompt engineering, we have an amazing selection of courses available in the Pluralsight platform. Just go to the platform and type in prompt engineering. You're going to get some wonderful courses. You can also go to platform.openai.com/docs/guides/gpt‑best‑practices. And you're going to discover a really cool documentation created by OpenAI that shows some of the best practices while writing your prompts. Thank you so much for taking the time, and have a beautiful day. I cannot wait to speak to you again in our next course. See you soon.
